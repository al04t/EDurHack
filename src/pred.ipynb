{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8b5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e328944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>estimated_woodchuck_population</th>\n",
       "      <th>VOLCF_AC_UNADJ</th>\n",
       "      <th>wood_chucked_per_woodchuck_lbs</th>\n",
       "      <th>total_wood_chucked_lbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>39.9</td>\n",
       "      <td>-75.6</td>\n",
       "      <td>3441.084157</td>\n",
       "      <td>17.493488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>39.9</td>\n",
       "      <td>-75.4</td>\n",
       "      <td>9445.985464</td>\n",
       "      <td>17.493488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>39.9</td>\n",
       "      <td>-75.3</td>\n",
       "      <td>7222.017160</td>\n",
       "      <td>17.493488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>39.9</td>\n",
       "      <td>-75.2</td>\n",
       "      <td>11869.568244</td>\n",
       "      <td>17.493488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>295.736902</td>\n",
       "      <td>97.186046</td>\n",
       "      <td>1.001197</td>\n",
       "      <td>296.090767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2024</td>\n",
       "      <td>41.9</td>\n",
       "      <td>-77.8</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3176.039981</td>\n",
       "      <td>39.681571</td>\n",
       "      <td>1984.078533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2024</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-80.2</td>\n",
       "      <td>292.625815</td>\n",
       "      <td>371.250695</td>\n",
       "      <td>4.444336</td>\n",
       "      <td>1300.527421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>2024</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-79.6</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>371.250695</td>\n",
       "      <td>4.444336</td>\n",
       "      <td>222.216796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2024</td>\n",
       "      <td>42.1</td>\n",
       "      <td>-80.1</td>\n",
       "      <td>6105.471860</td>\n",
       "      <td>371.250695</td>\n",
       "      <td>4.444336</td>\n",
       "      <td>27134.767856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2024</td>\n",
       "      <td>42.1</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>841.310743</td>\n",
       "      <td>371.250695</td>\n",
       "      <td>4.444336</td>\n",
       "      <td>3739.067547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  latitude  longitude  estimated_woodchuck_population  \\\n",
       "0    2018      39.9      -75.6                     3441.084157   \n",
       "1    2018      39.9      -75.4                     9445.985464   \n",
       "2    2018      39.9      -75.3                     7222.017160   \n",
       "3    2018      39.9      -75.2                    11869.568244   \n",
       "4    2018      40.0      -80.0                      295.736902   \n",
       "..    ...       ...        ...                             ...   \n",
       "899  2024      41.9      -77.8                       50.000000   \n",
       "900  2024      42.0      -80.2                      292.625815   \n",
       "901  2024      42.0      -79.6                       50.000000   \n",
       "902  2024      42.1      -80.1                     6105.471860   \n",
       "903  2024      42.1      -80.0                      841.310743   \n",
       "\n",
       "     VOLCF_AC_UNADJ  wood_chucked_per_woodchuck_lbs  total_wood_chucked_lbs  \n",
       "0         17.493488                        0.000000                0.000000  \n",
       "1         17.493488                        0.000000                0.000000  \n",
       "2         17.493488                        0.000000                0.000000  \n",
       "3         17.493488                        0.000000                0.000000  \n",
       "4         97.186046                        1.001197              296.090767  \n",
       "..              ...                             ...                     ...  \n",
       "899     3176.039981                       39.681571             1984.078533  \n",
       "900      371.250695                        4.444336             1300.527421  \n",
       "901      371.250695                        4.444336              222.216796  \n",
       "902      371.250695                        4.444336            27134.767856  \n",
       "903      371.250695                        4.444336             3739.067547  \n",
       "\n",
       "[904 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "[39.9, 40.0, 40.1, 40.2, 40.3, 40.4, 40.5, 40.6, 40.7, 40.8, 41.0, 41.1, 41.2, 41.5, 41.8, 41.9, 42.2, 39.7, 39.8, 40.9, 41.3, 41.6, 41.4, 41.7, 42.0, 42.1]\n"
     ]
    }
   ],
   "source": [
    "pop = pd.read_csv(r'C:\\Users\\User\\Desktop\\EDurHack\\Dataset\\cleanData\\woodchucks_with_wood_volume.csv')\n",
    "\n",
    "pop = pop.fillna(0)\n",
    "\n",
    "years = pop['year'].unique().tolist()\n",
    "\n",
    "lats = pop['latitude'].unique().tolist()\n",
    "\n",
    "display(pop)\n",
    "print(years)\n",
    "print(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d6d6ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m     final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwoodchuck_forecast_all.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df\n\u001b[1;32m---> 81\u001b[0m forecast(years, lats)\n",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mforecast\u001b[1;34m(years, lats)\u001b[0m\n\u001b[0;32m     53\u001b[0m future_time_index \u001b[38;5;241m=\u001b[39m [last_time_index \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m)]\n\u001b[0;32m     54\u001b[0m future_rolling \u001b[38;5;241m=\u001b[39m [location_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_mean_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m---> 55\u001b[0m future_X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: future_years,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_index\u001b[39m\u001b[38;5;124m'\u001b[39m: future_time_index,\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_mean_3\u001b[39m\u001b[38;5;124m'\u001b[39m: future_rolling\n\u001b[0;32m     59\u001b[0m     })\n\u001b[0;32m     61\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(future_X)\n\u001b[0;32m     62\u001b[0m future \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lat,\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "def forecast(years, lats):\n",
    "    all_results = []  # collect results across all years, lats, and lons\n",
    "\n",
    "    for year in years:\n",
    "        for lat in lats:\n",
    "            lons = pop[pop['latitude'] == lat]['longitude'].unique().tolist()\n",
    "            \n",
    "            for lon in lons:\n",
    "                location_data = pop[\n",
    "                    (pop['latitude'] == lat) &\n",
    "                    (pop['longitude'] == lon)\n",
    "                ].copy()\n",
    "                \n",
    "                location_data = location_data.sort_values('year').reset_index(drop=True)\n",
    "\n",
    "                location_data['time_index'] = range(len(location_data))\n",
    "                location_data['rolling_mean_3'] = (\n",
    "                    location_data['total_wood_chucked_lbs']\n",
    "                    .rolling(window=3, min_periods=1)\n",
    "                    .mean()\n",
    "                )\n",
    "\n",
    "                if len(location_data) < 3:\n",
    "                    last_year = location_data['year'].iloc[-1]\n",
    "                    last_value = location_data['total_wood_chucked_lbs'].iloc[-1]\n",
    "\n",
    "                    future = pd.DataFrame({\n",
    "                        'latitude': lat,\n",
    "                        'longitude': lon,\n",
    "                        'year': [last_year + i + 1 for i in range(16)],\n",
    "                        'total_wood_chucked_lbs': [last_value] * 16,\n",
    "                        'type': 'forecast'\n",
    "                    })\n",
    "\n",
    "                else:\n",
    "                    # Prepare training data (no lag features)\n",
    "                    X = location_data[['year', 'time_index', 'rolling_mean_3']]\n",
    "                    y = location_data['total_wood_chucked_lbs']\n",
    "                \n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=10,\n",
    "                    min_samples_split=2,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                model.fit(X, y)\n",
    "\n",
    "                last_year = location_data['year'].iloc[-1]\n",
    "                last_time_index = location_data['time_index'].iloc[-1]\n",
    "                \n",
    "                future_years = [last_year + i + 1 for i in range(16)]\n",
    "                future_time_index = [last_time_index + i + 1 for i in range(15)]\n",
    "                future_rolling = [location_data['rolling_mean_3'].iloc[-1]] * 15\n",
    "                future_X = pd.DataFrame({\n",
    "                        'year': future_years,\n",
    "                        'time_index': future_time_index,\n",
    "                        'rolling_mean_3': future_rolling\n",
    "                    })\n",
    "                \n",
    "                preds = model.predict(future_X)\n",
    "                future = pd.DataFrame({\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lon,\n",
    "                    'year': future_years,\n",
    "                    'total_wood_chucked_lbs': preds,\n",
    "                    'type': 'forecast'\n",
    "                })\n",
    "\n",
    "                # Combine historical and future\n",
    "                past = location_data[['latitude', 'longitude', 'year', 'total_wood_chucked_lbs']].copy()\n",
    "                past['type'] = 'historical'\n",
    "                combined = pd.concat([past, future])\n",
    "                all_results.append(combined)\n",
    "\n",
    "    final_df = pd.concat(all_results).sort_values(['year', 'latitude', 'longitude']).reset_index(drop=True)\n",
    "    final_df.to_csv(\"woodchuck_forecast_all.csv\", index=False)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "forecast(years, lats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
